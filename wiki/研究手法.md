# 研究手法

このページでは、LLMエラー修正分析プロジェクトの研究手法について詳しく説明します。

## 目次

1. [研究の背景](#研究の背景)
2. [仮説](#仮説)
3. [方法論](#方法論)
4. [分析手法](#分析手法)
5. [解釈](#解釈)

## 研究の背景

大規模言語モデル（LLM）は、テキスト生成や理解において驚異的な能力を示していますが、その内部メカニズムは「ブラックボックス」として扱われることが多いです。特に、モデルがどのようにエラーを検出し修正するかについては、まだ十分に理解されていません。

このプロジェクトでは、モデルの内部表現（活性化）を分析することで、エラー修正メカニズムの手がかりを探ります。

## 仮説

このプロジェクトの主な仮説は以下の通りです：

> 複数の異なる文ペアにおいて特定の次元（またはレイヤー）が一貫して小さな活性化変化を示す場合、それらの次元（またはレイヤー）がエラー修正に寄与している可能性がある。

つまり、入力の変化に対して「安定した」次元は、モデルがエラーを修正するために使用している可能性があります。

## 方法論

研究方法は以下の3つの主要なステップで構成されています：

### 1. 文ペアの作成

1つのトークンだけ異なる文のペアを生成し、タイプ別に分類します：

- **意味の違い**:
  - 主語の違い: "She loves coffee." vs "He loves coffee."
  - 場所の違い: "The cat sat on the mat." vs "The cat sat on the hat."
  - 形容詞の違い: "This is absolutely amazing." vs "This is absolutely terrible."

- **文法エラー**:
  - 時制エラー: "She was very tired yesterday." (正) vs "She is very tired yesterday." (誤)
  - 冠詞エラー: "He adopted a dog from the shelter." (正) vs "He adopted the dog from the shelter." (誤)
  - 前置詞エラー: "She is good at math." (正) vs "She is good in math." (誤)

これらの文ペアは、ChatGPT APIを使用して自動生成されます。

### 2. 活性化の抽出

生成された文ペアをLlama-3-7Bモデルに入力し、各レイヤーと次元の活性化を抽出します：

1. 各文をトークン化します
2. モデルに入力し、各レイヤーの活性化を記録します
3. 文ペア間の活性化の差異を計算します

### 3. 差異の分析

活性化の差異が最小となる次元を特定し、エラー修正行動を示す可能性があるかを分析します：

1. 各レイヤーと次元について、文ペア間の活性化差を計算します
2. 活性化差が最小となる次元を特定します
3. これらの次元が複数の文ペアタイプにわたって一貫しているかを分析します

## 分析手法

活性化差の分析には、以下の手法を使用します：

### 1. 活性化差の計算

各次元の活性化差は、以下の式で計算されます：

```
activation_diff = |activation_sentence1 - activation_sentence2|
```

### 2. 次元のランキング

各レイヤーの次元を活性化差でランク付けし、最小の活性化差を持つ次元を特定します。

### 3. クロスタイプ分析

異なる文ペアタイプにわたって、最小活性化差を持つ次元が一貫しているかを分析します。

### 4. 可視化

以下の可視化手法を使用して結果を分析します：

- ヒートマップ: 各レイヤーと次元の活性化差を視覚化
- 棒グラフ: 最小活性化差を持つ次元のランキング
- 散布図: 活性化差の分布

## 解釈

結果の解釈には、以下の観点から考察します：

1. **一貫性**: 特定の次元が複数の文ペアタイプにわたって一貫して小さな活性化差を示すか
2. **レイヤー特異性**: 特定のレイヤーが他のレイヤーよりも多くの「安定した」次元を持つか
3. **タイプ特異性**: 特定の文ペアタイプが他のタイプよりも多くの「安定した」次元を持つか

これらの観点から、モデルのエラー修正メカニズムについての洞察を得ることを目指します。

## 次のステップ

研究手法を理解したら、[トラブルシューティング](トラブルシューティング)ページに進んで、一般的な問題と解決策を確認してください。
